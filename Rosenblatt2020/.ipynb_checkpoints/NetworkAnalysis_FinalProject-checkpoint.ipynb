{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presettings ################################################################\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import os\n",
    "from spreading_CR import SpreadingProcess #https://github.com/gstonge/spreading_CR/blob/master/README.md\n",
    "\n",
    "# Set working directory\n",
    "#os.chdir('/Users/johannaregenthal/Documents/GitHub/NetworkAnalysis/Rosenblatt2020')\n",
    "\n",
    "# User-defined functions\n",
    "\n",
    "def create_random_networks(original_graph, number):\n",
    "    \"\"\"\n",
    "    Function to create several random graphs based on one original graph.\n",
    "    Returns list of random graphs\n",
    "    \"\"\"\n",
    "    # Get degree sequence from original graph\n",
    "    degree_sequence = [d for n, d in original_graph.degree()]\n",
    "\n",
    "    # Create true configuration networks without self-loops and parallel edges\n",
    "    N = 0\n",
    "    graphs = []\n",
    "    while N < number:\n",
    "        #Sample from original degree_sequence\n",
    "        deg_sequence_sample = random.sample(degree_sequence, n)\n",
    "        #Check for valid degree sequence\n",
    "        if nx.is_graphical(deg_sequence_sample):\n",
    "            G_random = nx.configuration_model(deg_sequence_sample, create_using = nx.Graph())\n",
    "            graphs.append(G_random)\n",
    "            N += 1\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def create_networkcopy_with_missing_nodes(graph, list_missing_percentages):\n",
    "    \"\"\"\n",
    "    Function to return a list of graphs which have missing nodes based on a given list.\n",
    "        graph = true network\n",
    "        list_missing_percentages = list that contains the percentages of which the observed networks should be created\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for p in list_missing_percentages:\n",
    "        G = graph.copy()\n",
    "        G.remove_nodes_from(random.sample(list(G.nodes()), int(len(graph.nodes()) * p)))\n",
    "        lst.append((G, p))\n",
    "    return lst\n",
    "\n",
    "\n",
    "\n",
    "def sim_infection(graph, immune_nodes, unimmune_nodes, numOfSimulations, beta, gamma, seed):\n",
    "    final_size_list = []\n",
    "    \n",
    "    # patient0s should be nodes which have at least one neighbor, otherwise sp.initialize will throw an error, so we first check can be used\n",
    "    nodes_with_neighbors = [node for node, degree in nx.degree_centrality(graph).items() if degree > 0] \n",
    "    array_patient0s = np.random.choice(nodes_with_neighbors, size=numOfSimulations)\n",
    "    \n",
    "    list_patient0s = [[patient0] for patient0 in array_patient0s] \n",
    "    \n",
    "    sp = SpreadingProcess(list(graph.edges()), beta, gamma, 0)\n",
    "    # Start simulations\n",
    "    for i in range(numOfSimulations): \n",
    "        #Inode_list = list_patient0s[i]\n",
    "        sp.initialize(list_patient0s[i], immune_nodes, seed)\n",
    "        sp.evolve(np.inf)\n",
    "        \n",
    "        finalSizeInclTargets = sp.get_Rnode_number_vector()[-1]\n",
    "        adjustedFinalSize = finalSizeInclTargets -  len(immune_nodes)\n",
    "        final_size_list.append(adjustedFinalSize) # final_size_list = Number of infected nodes per simulation\n",
    "        sp.reset()\n",
    "    \n",
    "    # Outbreak size = % of nodes that are recovered/immune and were infected\n",
    "    pctTotalPopInf_mean = np.mean(final_size_list) / 1000 #graph.number_of_nodes() # outbreak size in % \n",
    "    pctTotalPopInf_std = np.std(final_size_list) / 1000 #graph.number_of_nodes() # std of outbreak size\n",
    "    \n",
    "    return [pctTotalPopInf_mean, pctTotalPopInf_std]\n",
    "\n",
    "# Predefine parameters\n",
    "P = np.arange(0, 0.9, 0.1) #Part of missing nodes (error level 0 - 80%)\n",
    "q = 0.1 #Fraction of immunized nodes = 10%\n",
    "n = 1000 #Number of nodes = 1000\n",
    "\n",
    "# Outbreak parameters\n",
    "beta = 0.95\n",
    "gamma = 1\n",
    "\n",
    "# centrality measure (functions)\n",
    "# comparing to random \n",
    "#Degree\n",
    "#Betweenness\n",
    "#Eigenvector\n",
    "#PageRank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random networks ###################################################\n",
    "\n",
    "# Import network data\n",
    "data = pd.read_csv('edgelist.truecolsprings.csv', usecols = ['V1', 'V2'])\n",
    "nodes = list(set(data.V1).union(set(data.V2)))\n",
    "edges = list(zip(data.V1, data.V2))\n",
    "\n",
    "# Create Colorado Springs network\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "#print(nx.info(G))\n",
    "\n",
    "graphs = create_random_networks(G, 1000)\n",
    "\n",
    "# delete unnecessary variables\n",
    "del data, nodes, edges, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.0 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simulations ################################################################\n",
    "listing = []\n",
    "num_SIR = 2000\n",
    "MAX_CPLUSPLUS_INT = 4294967295\n",
    "\n",
    "# For each true network\n",
    "for G_true in graphs[:5]:\n",
    "    # For each observed network with p% missing nodes\n",
    "    for G_observed, p in create_networkcopy_with_missing_nodes(G_true, P):\n",
    "        seed = np.random.randint(MAX_CPLUSPLUS_INT+1)\n",
    "        num_immune_nodes = int(len(G_observed.nodes) * q)\n",
    "        print(G_observed.number_of_nodes(), p, num_immune_nodes)\n",
    "        \n",
    "        #Simulation with no immunization\n",
    "        mean_noImm, std_noImm = sim_infection(G_observed, [], list(G_observed.nodes), num_SIR, beta, gamma, seed)\n",
    "        \n",
    "        #Random immunization\n",
    "        immune_nodes = random.sample(list(G_observed.nodes), num_immune_nodes) # Select q% of nodes for immunization\n",
    "        unimmune_nodes = list(set(G_observed.nodes) - set(immune_nodes))\n",
    "        mean_ran, std = sim_infection(G_observed, immune_nodes, unimmune_nodes, num_SIR, beta, gamma, seed)\n",
    "        \n",
    "        #Degree immunization\n",
    "        dic_degree = nx.degree_centrality(G_observed) \n",
    "        immune_nodes = sorted(dic_degree, key=dic_degree.get, reverse=True)[:num_immune_nodes]\n",
    "        unimmune_nodes = list(set(G_observed.nodes) - set(immune_nodes))\n",
    "        mean_deg, std = sim_infection(G_observed, immune_nodes, unimmune_nodes, num_SIR, beta, gamma, seed)\n",
    "        \n",
    "        #Betweenness immunization\n",
    "        dic_betweeness = nx.betweenness_centrality(G_observed) \n",
    "        immune_nodes = sorted(dic_betweeness, key=dic_degree.get, reverse=True)[:num_immune_nodes]\n",
    "        unimmune_nodes = list(set(G_observed.nodes) - set(immune_nodes))\n",
    "        mean_bet, std = sim_infection(G_observed, immune_nodes, unimmune_nodes, num_SIR, beta, gamma, seed)\n",
    "        \n",
    "        #Eigenvector immunization\n",
    "        dic_eigen = nx.eigenvector_centrality(G_observed) \n",
    "        immune_nodes = sorted(dic_eigen, key=dic_degree.get, reverse=True)[:num_immune_nodes]\n",
    "        unimmune_nodes = list(set(G_observed.nodes) - set(immune_nodes))\n",
    "        mean_eig, std = sim_infection(G_observed, immune_nodes, unimmune_nodes, num_SIR, beta, gamma, seed)\n",
    "        \n",
    "        #Pagerank immunization\n",
    "        dic_pagerank = nx.pagerank(G_observed) \n",
    "        immune_nodes = sorted(dic_pagerank, key=dic_degree.get, reverse=True)[:num_immune_nodes]\n",
    "        unimmune_nodes = list(set(G_observed.nodes) - set(immune_nodes))\n",
    "        mean_page, std = sim_infection(G_observed, immune_nodes, unimmune_nodes, num_SIR, beta, gamma, seed)\n",
    "     \n",
    "        \n",
    "        listing.append([G_observed.number_of_nodes(), p, mean_noImm, mean_ran, mean_deg, mean_bet, mean_eig, mean_page])\n",
    "\n",
    "df = pd.DataFrame(listing, \n",
    "                  columns=['graphsize', 'p', 'mean_noImm', 'mean_ran', 'mean_deg', 'mean_bet', 'mean_eig', 'mean_page'])\n",
    "\n",
    "df.groupby('p')['mean_ran'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
